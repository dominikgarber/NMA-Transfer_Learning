{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_vgg11_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3OwP6vjvkoYZ7OZicD6aX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dominikgarber/NMA-Transfer_Learning/blob/main/load_vgg11_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "CcIQXHUkNgCM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## load VGG11\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg11', pretrained=False)\n",
        "model.eval() # shows structure of network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp3kXH0xPvf9",
        "outputId": "f25b9f61-aa70-408c-e774-fc5fb6a45049"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing In/Out Dimensions"
      ],
      "metadata": {
        "id": "YSB3KP0oh8CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change Nr of output units\n",
        "in_ftrs = model.classifier[6].in_features # number of input features of the last layer of the classifier\n",
        "print(\"+ Previous Nr of Outputs: \" + str(model.classifier[6].out_features)) # number of output features of the last layer of the classifier == num_classes\n",
        "model.classifier[6] = nn.Linear(in_ftrs, 100)\n",
        "print(\"++++++ New Nr of Outputs: \" + str(model.classifier[6].out_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x46PHkjFOX-_",
        "outputId": "65fcda36-7da8-46c2-eaac-0d8fba8103f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ Previous Nr of Outputs: 1000\n",
            "++++++ New Nr of Outputs: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change Size of Input\n",
        "model.features[0]\n",
        "\n",
        "# in nn.Conv2d you only need to specific the nr of input channels, not the height and width. \n",
        "# The image size is set to a minimum of 32x32 in the VGG class, but I don't understand how that works yet.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM1QmsrtOaD8",
        "outputId": "9074dd66-b35a-4a27-b6e6-91869e6b5a9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test model on random input (just see if there is no error)\n",
        "y = model(Variable(torch.randn(1,3,32,32)))"
      ],
      "metadata": {
        "id": "Y6GDIoWMOdFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freezing/Unfreezing"
      ],
      "metadata": {
        "id": "OpLPFt9riFi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inital Nr of total and trainable parameters (they are equal here)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('Total Parameters:', total_params, 'Trainable parameters: ', trainable_total_params)"
      ],
      "metadata": {
        "id": "Z9XOXgvhPjJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b9c319-5ad8-4a20-ec91-9f91791e1291"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 129176036 Trainable parameters:  129176036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freez all layers\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "vDsoJ8bqb2eg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated Nr of total and trainable parameters (nothing is trainable anymore)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('Total Parameters:', total_params, 'Trainable parameters: ', trainable_total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlRVW62tdOb5",
        "outputId": "f4e66b88-4fb8-4fb2-f9e8-050df68d530e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 129176036 Trainable parameters:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all parameters of last layer\n",
        "for param in model.classifier[6].parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "i6rLWqloeDdu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated Nr of total and trainable parameters (last layer is trainable)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('Total Parameters:', total_params, 'Trainable parameters: ', trainable_total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uK6hfIndbkF",
        "outputId": "ac77180e-d8df-4c1b-dd65-bc216d001bfb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 129176036 Trainable parameters:  409700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 409700 paramerts makes sense for the last layer as it has 4096 inputs and maps to 100 outputs (classes).\n",
        "# The nr of parameters is 4096*100 weights + 100 biases"
      ],
      "metadata": {
        "id": "5PHvcfLgfDha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreez all layers again\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "2IQXDILlhpMV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated Nr of total and trainable parameters (everything trainable again)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('Total Parameters:', total_params, 'Trainable parameters: ', trainable_total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-0zHPrlhvIa",
        "outputId": "d545c6d8-f43c-4629-d124-fc99896070ee"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 129176036 Trainable parameters:  129176036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Train Network\n"
      ],
      "metadata": {
        "id": "YqyYU-Mqh0r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Add Data loader ###\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WuC_omisqF73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)"
      ],
      "metadata": {
        "id": "9rtfppfoizbF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set deive\n",
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "metadata": {
        "id": "gMDfAVkrjFmk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed=2021)\n",
        "device = set_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7os57Q-ijMDx",
        "outputId": "fcd563d1-d6dd-4dc0-a65d-42ffdcec5f23"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters and setup\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "batch_size = 128\n",
        "max_epochs = 15  # Please change this to 200\n",
        "#max_epochs_target = 10\n",
        "base_learning_rate = 0.1\n",
        "torchvision_transforms = True  # True/False if you want use torchvision augmentations"
      ],
      "metadata": {
        "id": "7JoxgOLjjSH2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_folder = './results/'\n",
        "if not os.path.exists(result_folder):\n",
        "    os.makedirs(result_folder)\n",
        "\n",
        "logname = result_folder + model.__class__.__name__ + '_pretrain' + '.csv'\n",
        "\n",
        "if use_cuda:\n",
        "  model.cuda()\n",
        "  net = torch.nn.DataParallel(model)\n",
        "  print('Using', torch.cuda.device_count(), 'GPUs.')\n",
        "  cudnn.benchmark = True\n",
        "  print('Using CUDA..')"
      ],
      "metadata": {
        "id": "CuVi8zMLh3wc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer and criterion\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=base_learning_rate, momentum=0.9, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "WuAMENhRjepz"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training & Test functions\n",
        "\n",
        "def train(net, epoch, use_cuda=True):\n",
        "  print('\\nEpoch: %d' % epoch)\n",
        "  net.train()\n",
        "  train_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "    if use_cuda:\n",
        "      inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    inputs, targets = Variable(inputs), Variable(targets)\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += targets.size(0)\n",
        "    correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "    if batch_idx % 500 == 0:\n",
        "      print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "  return (train_loss/batch_idx, 100.*correct/total)\n",
        "\n",
        "\n",
        "def test(net, epoch, outModelName, use_cuda=True):\n",
        "  global best_acc\n",
        "  net.eval()\n",
        "  test_loss, correct, total = 0, 0, 0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "      if use_cuda:\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += targets.size(0)\n",
        "      correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "      if batch_idx % 200 == 0:\n",
        "        print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "  # Save checkpoint.\n",
        "  acc = 100.*correct/total\n",
        "  if acc > best_acc:\n",
        "    best_acc = acc\n",
        "    checkpoint(net, acc, epoch, outModelName)\n",
        "  return (test_loss/batch_idx, 100.*correct/total)"
      ],
      "metadata": {
        "id": "dlM3UlkGjoLq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint & adjust_learning_rate\n",
        "def checkpoint(model, acc, epoch, outModelName):\n",
        "  # Save checkpoint.\n",
        "  print('Saving..')\n",
        "  state = {\n",
        "      'state_dict': model.state_dict(),\n",
        "      'acc': acc,\n",
        "      'epoch': epoch,\n",
        "      'rng_state': torch.get_rng_state()\n",
        "  }\n",
        "  if not os.path.isdir('checkpoint'):\n",
        "      os.mkdir('checkpoint')\n",
        "  torch.save(state, f'./checkpoint/{outModelName}.t7')\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "  \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
        "  lr = base_learning_rate\n",
        "  if epoch <= 9 and lr > 0.1:\n",
        "    # warm-up training for large minibatch\n",
        "    lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n",
        "  if epoch >= 100:\n",
        "    lr /= 10\n",
        "  if epoch >= 150:\n",
        "    lr /= 10\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "Hrcqkzbppnu4"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "outModelName = 'pretrain'\n",
        "if not os.path.exists(logname):\n",
        "  with open(logname, 'w') as logfile:\n",
        "      logwriter = csv.writer(logfile, delimiter=',')\n",
        "      logwriter.writerow(['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n",
        "\n",
        "for epoch in range(start_epoch, max_epochs):\n",
        "  adjust_learning_rate(optimizer, epoch)\n",
        "  train_loss, train_acc = train(net, epoch, use_cuda=use_cuda)\n",
        "  test_loss, test_acc = test(net, epoch, outModelName, use_cuda=use_cuda)\n",
        "  with open(logname, 'a') as logfile:\n",
        "    logwriter = csv.writer(logfile, delimiter=',')\n",
        "    logwriter.writerow([epoch, train_loss, train_acc.item(), test_loss, test_acc.item()])\n",
        "  print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')"
      ],
      "metadata": {
        "id": "e3wvCJSaqAUp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}