{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tansfer_Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAFgUlUXKRnKeaHImkd743",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gaojundong/NMA-Transfer_Learning/blob/main/Tansfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8bFDIJdCbgni"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import csv\n",
        "import glob\n",
        "import torch\n",
        "import multiprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_device():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device"
      ],
      "metadata": {
        "id": "UuIFlpSxcgjz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n"
      ],
      "metadata": {
        "id": "aQSBY_4WCajL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "set_seed(seed=2022)\n",
        "device = set_device()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXtPgZOdd2jc",
        "outputId": "f1e78a80-aefe-48eb-f00f-9b3cbc45690b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2022 has been set.\n",
            "GPU is enabled in this notebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "use_cuda = torch.cuda.is_available()\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "batch_size = 128\n",
        "max_epochs = 15  # Please change this to 200\n",
        "max_epochs_target = 10\n",
        "base_learning_rate = 0.1\n",
        "torchvision_transforms = True  # True/False if you want use torchvision augmentations"
      ],
      "metadata": {
        "id": "1Ri5IJZLCr4L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing data\n",
        "\n",
        "print('==> Preparing data..')\n",
        "def percentageSplit(full_dataset, percent = 0.0):\n",
        "  set1_size = int(percent * len(full_dataset))\n",
        "  set2_size = len(full_dataset) - set1_size\n",
        "  final_dataset, _ = torch.utils.data.random_split(full_dataset, [set1_size, set2_size])\n",
        "  return final_dataset\n",
        "\n",
        "\n",
        "# normalizing we need to calculate \n",
        "mean = [0.5071, 0.4866, 0.4409]\n",
        "std = [0.2673, 0.2564, 0.2762]\n",
        "\n",
        "# torchvision transforms\n",
        "transform_train = transforms.Compose([])\n",
        "if torchvision_transforms:\n",
        "  transform_train.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "  transform_train.transforms.append(transforms.RandomHorizontalFlip())\n",
        "\n",
        "transform_train.transforms.append(transforms.ToTensor())\n",
        "transform_train.transforms.append(transforms.Normalize(mean, std))\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "# trainset = torchvision.datasets.CIFAR100(\n",
        "#   root='./CIFAR100', train=True, download=True, transform=transform_train)\n",
        "\n",
        "\n",
        "\n",
        "# testset = torchvision.datasets.CIFAR100(\n",
        "#   root='./CIFAR100', train=False, download=True, transform=transform_test)"
      ],
      "metadata": {
        "id": "4392AXSsC4ez"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}